{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOfLsbBl5QK+wHkCLfK9M35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaubs/ds22/blob/master/notebooks/m3_ws_intro_tstf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF2VPA-Axx2O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before starting, we define some constants\n",
        "figsize = (9, 6)\n",
        "lowest_q, low_q, high_q, highest_q = 0.01, 0.1, 0.9, 0.99\n",
        "label_q_outer = f\"{int(lowest_q * 100)}-{int(highest_q * 100)}th percentiles\"\n",
        "label_q_inner = f\"{int(low_q * 100)}-{int(high_q * 100)}th percentiles\""
      ],
      "metadata": {
        "id": "zzSLdmQpHGKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Transformer-based Timeseries Forecast"
      ],
      "metadata": {
        "id": "OSOqg2C-Gx5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal Fusion Transformers"
      ],
      "metadata": {
        "id": "oXFgP1uoNGug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "L8iSEax1ORax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "xxx\n",
        "xxx\n",
        "xxx"
      ],
      "metadata": {
        "id": "41dszDbmcItE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timesieries implementation (DARTS)\n",
        "\n",
        "darts is a Python library for easy manipulation and forecasting of time series. It contains a variety of models, from classics such as ARIMA to deep neural networks. The models can all be used in the same way, using fit() and predict() functions, similar to scikit-learn. The library also makes it easy to backtest models, combine the predictions of several models, and take external data into account. Darts supports both univariate and multivariate time series and models. The ML-based models can be trained on potentially large datasets containing multiple time series, and some of the models offer a rich support for probabilistic forecasting."
      ],
      "metadata": {
        "id": "9TF87dp1cNCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install darts"
      ],
      "metadata": {
        "id": "c4rGjQpltPCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from darts import TimeSeries, concatenate\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "from darts.models import TFTModel\n",
        "from darts.metrics import mape\n",
        "from darts.utils.statistics import check_seasonality, plot_acf\n",
        "from darts.datasets import AirPassengersDataset, IceCreamHeaterDataset\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "from darts.utils.likelihood_models import QuantileRegression\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "sOUbckxkq5WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Darts’ TFTModel incorporates the following main components from the original Temporal Fusion Transformer (TFT) architecture:\n",
        "\n",
        "*gating mechanisms: skip over unused components of the model architecture\n",
        "* variable selection networks: select relevant input variables at each time step.\n",
        "* temporal processing of past and future input with LSTMs (long short-term memory)\n",
        "* multi-head attention: captures long-term temporal dependencies\n",
        "* prediction intervals: per default, produces quantile forecasts instead of deterministic values"
      ],
      "metadata": {
        "id": "ri_OK8zJcLe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "TFTModel can be trained with past and future covariates. It is trained sequentially on fixed-size chunks consisting of an encoder and a decoder part:\n",
        "\n",
        "* encoder: past input with input_chunk_length\n",
        "  * past target: mandatory\n",
        "  * past covariates: optional\n",
        "* decoder: future known input with output_chunk_length\n",
        "  * future covariates: mandatory (if none are available, consider TFTModel’s optional arguments add_encoders or add_relative_index from here)\n",
        "\n",
        "In each iteration, the model produces a quantile prediction of shape (output_chunk_length, n_quantiles) on the decoder part."
      ],
      "metadata": {
        "id": "nVb3GBVjrHLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forecast\n",
        "\n",
        "Per default, TFTModel produces probabilistic quantile forecasts using QuantileRegression. This gives the range of likely target values at each prediction step. Most deep learning models in Darts’ - including TFTModel - support QuantileRegression and 16 other likelihoods to produce probabilistic forecasts by setting likelihood=MyLikelihood() at model creation."
      ],
      "metadata": {
        "id": "IMpsYb3ErnjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toy example (Air Passangers)\n",
        "\n",
        "Adopted from the [DARTS pakage tutorial](https://unit8co.github.io/darts/examples/13-TFT-examples.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "eDCfU0H7qeGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data set that is highly dependent on covariates. Knowing the month tells us a lot about the seasonal component, whereas the year determines the effect of the trend component.\n",
        "\n",
        "Additionally, let’s convert the time index to integer values and use them as covariates as well.\n",
        "\n",
        "All of the three covariates are known in the future, and can be used as future_covariates with the TFTModel."
      ],
      "metadata": {
        "id": "nWfNzvjvrZo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "series = AirPassengersDataset().load()"
      ],
      "metadata": {
        "id": "x59sstycMDww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series.head()"
      ],
      "metadata": {
        "id": "yRodLz0uaqXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we convert monthly number of passengers to average daily number of passengers per month\n",
        "series = series / TimeSeries.from_series(series.time_index.days_in_month)\n",
        "series = series.astype(np.float32)"
      ],
      "metadata": {
        "id": "sjGTWStca2Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation sets:\n",
        "training_cutoff = pd.Timestamp(\"19571201\")\n",
        "train, val = series.split_after(training_cutoff)"
      ],
      "metadata": {
        "id": "2Jbc0q8Ma5jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the time series (note: we avoid fitting the transformer on the validation set)\n",
        "transformer = Scaler()\n",
        "train_transformed = transformer.fit_transform(train)\n",
        "val_transformed = transformer.transform(val)\n",
        "series_transformed = transformer.transform(series)"
      ],
      "metadata": {
        "id": "XKnI5IyMa-9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create year, month and integer index covariate series\n",
        "covariates = datetime_attribute_timeseries(series, attribute=\"year\", one_hot=False)"
      ],
      "metadata": {
        "id": "M7RbIfeybEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covariates = covariates.stack(datetime_attribute_timeseries(series, attribute=\"month\", one_hot=False))"
      ],
      "metadata": {
        "id": "CIcY6-eMbPiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covariates = covariates.stack(\n",
        "    TimeSeries.from_times_and_values(\n",
        "        times=series.time_index,\n",
        "        values=np.arange(len(series)),\n",
        "        columns=[\"linear_increase\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "covariates = covariates.astype(np.float32)"
      ],
      "metadata": {
        "id": "06KqSxxobTt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_train, cov_val = covariates.split_after(training_cutoff)"
      ],
      "metadata": {
        "id": "pgXzx74Qbise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform covariates (note: we fit the transformer on train split and can then transform the entire covariates series)\n",
        "scaler_covs = Scaler()\n",
        "scaler_covs.fit(cov_train)\n",
        "covariates_transformed = scaler_covs.transform(covariates)"
      ],
      "metadata": {
        "id": "zkrj3fje6liS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TFTModel can only be used if some future input is given. Optional parameters add_encoders and add_relative_index can be useful, especially if we don’t have any future input available. They generate endoded temporal data is used as future covariates.\n",
        "\n",
        "Since we already have future covariates defined in our example they are commented out."
      ],
      "metadata": {
        "id": "EeHOKKY7sWYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 200\n",
        "input_chunk_length = 24\n",
        "forecast_horizon = 12"
      ],
      "metadata": {
        "id": "AnMc0Tr37HA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = TFTModel(\n",
        "    input_chunk_length=input_chunk_length,\n",
        "    output_chunk_length=forecast_horizon,\n",
        "    hidden_size=64,\n",
        "    lstm_layers=1,\n",
        "    num_attention_heads=4,\n",
        "    dropout=0.1,\n",
        "    batch_size=16,\n",
        "    n_epochs=300,\n",
        "    add_relative_index=False,\n",
        "    add_encoders=None,\n",
        "    likelihood=QuantileRegression(\n",
        "        # quantiles= [ 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
        "    ),  # QuantileRegression is set per default\n",
        "    # loss_fn=MSELoss(),\n",
        "    random_state=42,\n",
        ")"
      ],
      "metadata": {
        "id": "ku5pnZ8L7Nal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In what follows, we can just provide the whole covariates series as future_covariates argument to the model; the model will slice these covariates and use only what it needs in order to train on forecasting the target train_transformed:"
      ],
      "metadata": {
        "id": "7fHejuSQsj06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.fit(train_transformed, future_covariates=covariates_transformed, verbose=True)"
      ],
      "metadata": {
        "id": "7Oo9tYK37Sxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform a one-shot prediction of 24 months using the “current” model - i.e., the model at the end of the training procedure:"
      ],
      "metadata": {
        "id": "b2dBxj_Rsscc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, n, actual_series, val_series):\n",
        "    pred_series = model.predict(n=n, num_samples=num_samples)\n",
        "\n",
        "    # plot actual series\n",
        "    plt.figure(figsize=figsize)\n",
        "    actual_series[: pred_series.end_time()].plot(label=\"actual\")\n",
        "\n",
        "    # plot prediction with quantile ranges\n",
        "    pred_series.plot(\n",
        "        low_quantile=lowest_q, high_quantile=highest_q, label=label_q_outer\n",
        "    )\n",
        "    pred_series.plot(low_quantile=low_q, high_quantile=high_q, label=label_q_inner)\n",
        "\n",
        "    plt.title(\"MAPE: {:.2f}%\".format(mape(val_series, pred_series)))\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "HGpnsOFl7haz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(my_model, 24, series_transformed, val_transformed)"
      ],
      "metadata": {
        "id": "-OAUz7T37m9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s backtest our TFTModel model, to see how it performs with a forecast horizon of 12 months over the last 3 years:"
      ],
      "metadata": {
        "id": "VTOLk8SPsyAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backtest_series = my_model.historical_forecasts(\n",
        "    series_transformed,\n",
        "    future_covariates=covariates_transformed,\n",
        "    start=train.end_time() + train.freq,\n",
        "    num_samples=num_samples,\n",
        "    forecast_horizon=forecast_horizon,\n",
        "    stride=forecast_horizon,\n",
        "    last_points_only=False,\n",
        "    retrain=False,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "e3fskAmPs33Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_backtest(backtest_series, actual_series, horizon, start, transformer):\n",
        "    plt.figure(figsize=figsize)\n",
        "    actual_series.plot(label=\"actual\")\n",
        "    backtest_series.plot(\n",
        "        low_quantile=lowest_q, high_quantile=highest_q, label=label_q_outer\n",
        "    )\n",
        "    backtest_series.plot(low_quantile=low_q, high_quantile=high_q, label=label_q_inner)\n",
        "    plt.legend()\n",
        "    plt.title(f\"Backtest, starting {start}, {horizon}-months horizon\")\n",
        "    print(\n",
        "        \"MAPE: {:.2f}%\".format(\n",
        "            mape(\n",
        "                transformer.inverse_transform(actual_series),\n",
        "                transformer.inverse_transform(backtest_series),\n",
        "            )\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "oS8JNCS8s89h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_backtest(\n",
        "    backtest_series=concatenate(backtest_series),\n",
        "    actual_series=series_transformed,\n",
        "    horizon=forecast_horizon,\n",
        "    start=training_cutoff,\n",
        "    transformer=transformer,\n",
        ")"
      ],
      "metadata": {
        "id": "8WlzMutZtAlm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}