---
title: "Sentence-Transformers SBERT"
weight: 2
disableToc: true
draft: false
---

![](https://source.unsplash.com/vuMTQj6aQQ0)

Sentence Transformers are a recent breakthrough in natural language processing that can generate dense, high-quality embeddings of sentences, enabling accurate semantic similarity comparisons between sentences. What makes them particularly exciting for businesses and social science applications is their ability to enable more intuitive, meaningful language-based search, content deduplication, and clustering. With Sentence Transformers, businesses can enhance the accuracy of their search engines, provide more accurate recommendations, and reduce redundancy in content databases. Social science researchers can use Sentence Transformers to identify commonalities between texts and to cluster documents to identify trends and topics in large corpora.

## Resources

- OG SBERT-Paper [Reimers, N., & Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084.](https://arxiv.org/abs/1908.10084)

- [SBERT Docu](https://www.sbert.net)

- [NLP with SBERT](https://www.pinecone.io/learn/nlp/) - an ebook/course on the use of dense vectors (with SBERT for business applications)

- [SBERT-Training Tutorial](https://huggingface.co/blog/how-to-train-sentence-transformers)

- [BERTopic](https://maartengr.github.io/BERTopic/index.html) - a framework for topic modelling with SBERT embeddings

- [Milvus - Vector database](https://milvus.io)

## Slides




