---
title: "Exercise 2: Performing a Big Data workflow with Spark and Polars"
weight: 2
disableToc: true
draft: false
---

<img src="https://raw.githubusercontent.com/aaubs/ds-master/main/data/Images/Spark.png" width="20">

In this session, we will demonstrate how to use Apache Spark, a powerful Big Data processing engine, for processing large datasets in ML projects. The session will cover tasks such as setting up a Spark environment, reading and writing data, and performing transformations and aggregations on data. Additionally, we will also introduce Polars, a similar data manipulation library for Rust, and compare its features to those of Spark.

This session will provide hands-on exercises to reinforce your understanding and skills in working with Spark and Polars for processing big data in ML projects.





## Notebooks

* [Performing a Big Data workflow with Pandas and Polars](https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M6_Performing_a_Big_Data_workflow_with_Pandas_and_Polars.ipynb)
* [Performing a Big Data workflow with Polars - Into](https://colab.research.google.com/github/aaubs/ds-master/blob/main/notebooks/M6_Performing_a_Big_Data_workflow_with_Polars_Into.ipynb)
* [Performing a Big Data workflow with Pandas and Polars]()
* [Performing a Big Data workflow with Pandas and Polars]()




