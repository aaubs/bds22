<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Rransformer models in 2023 on Social / Business Data Science 2022</title><link>https://aaubs.github.io/ds22/m4/04_transformer/</link><description>Recent content in Rransformer models in 2023 on Social / Business Data Science 2022</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://aaubs.github.io/ds22/m4/04_transformer/index.xml" rel="self" type="application/rss+xml"/><item><title>Fine-tuning transformers</title><link>https://aaubs.github.io/ds22/m4/04_transformer/1_basictm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds22/m4/04_transformer/1_basictm/</guid><description>Resources You will need a HFðŸ¤— account to upload models We will use W&amp;amp;amp;B for monitoring - get an account if you like to follow that part Notebooks Transformer-based Translation (inference)
Finetuning Sequence Classification with Bert</description></item></channel></rss>