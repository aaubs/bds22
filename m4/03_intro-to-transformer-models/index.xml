<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Intro to transformer models on Social / Business Data Science 2022</title><link>https://aaubs.github.io/ds22/m4/03_intro-to-transformer-models/</link><description>Recent content in Intro to transformer models on Social / Business Data Science 2022</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://aaubs.github.io/ds22/m4/03_intro-to-transformer-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to transformers</title><link>https://aaubs.github.io/ds22/m4/03_intro-to-transformer-models/1_basictm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aaubs.github.io/ds22/m4/03_intro-to-transformer-models/1_basictm/</guid><description>Literature Sutskever, I., Vinyals, O., &amp;amp;amp; Le, Q. V. (2014). Sequence to sequence learning with neural networks. Advances in neural information processing systems, 27.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., &amp;amp;hellip; &amp;amp;amp; Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.
The illustrated transformer
Simple transformer LM
Notebooks Seq2Seq - Neural Machine Translation
Simple transformer LM</description></item></channel></rss>